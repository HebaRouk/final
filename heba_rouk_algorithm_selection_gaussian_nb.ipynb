{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HebaRouk/final/blob/main/heba_rouk_algorithm_selection_gaussian_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP9uQN0Q0-Wf"
      },
      "source": [
        "\n",
        "# Challenge of the Week: Gaussian Naive Bayes Classifier\n",
        "---\n",
        "Â© 2024, Zaka AI, Inc. All Rights Reserved.\n",
        "\n",
        "##**Case Study:** Iris Dataset\n",
        "\n",
        "**Objective:** The objective of this challenge is to make you know about Naive Bayes applied on Numerical Values.\n",
        "\n",
        "**DataSet Columns:**<br>\n",
        "*\t Petal Height\n",
        "*  Petal Width\n",
        "*  Sepal Height\n",
        "*  Sepal Width\n",
        "*  Target: The kind of the Iris flower (Virginica, Setosa, Versicolor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHi57nVC1Yn2"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXaV5FCRD0Yt"
      },
      "source": [
        "Start by importing the necessary libraries. For this problem we need the following:\n",
        "\n",
        "\n",
        "*   Numpy: for numerical calculations\n",
        "*   Pandas: to deal with the dataset\n",
        "*   math: to work on the mathematical aspects of Naive Bayes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3lTMdVK07ES"
      },
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np   # For numerical calculations\n",
        "import pandas as pd  # To handle datasets\n",
        "import math          # For mathematical computations in Naive Bayes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntP2fLal1cGQ"
      },
      "source": [
        "# Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGMF3f-KEexZ"
      },
      "source": [
        "Load the dataset in your environment. One thing to note is that the dataset you have does not include names for different columns. This is why you should name the columns by hand as ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']. Then don't forget to show the head of your dataset to get a better insight into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzNYyltN1X9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df88c1b4-58be-494c-a6c3-9feb7378a290"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define column names\n",
        "column_names = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']\n",
        "\n",
        "# Check the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the current directory\n",
        "print(\"Files in the directory:\", os.listdir())\n",
        "\n",
        "# Attempt to load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('iris(1).csv', header=None, names=column_names)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    # Display the first few rows of the dataset\n",
        "    print(\"First five rows of the dataset:\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Files in the directory: ['.config', 'iris (1).xlsx', 'sample_data']\n",
            "Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE5Znmrh5nW4"
      },
      "source": [
        "##Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cKCe7P7DYi"
      },
      "source": [
        "You may have noticed that the Target Column contains string values rather than numbers. This is why, you will Change the string values to numerical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8eT9I255p7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854ea1f1-88d8-413d-a166-8028c3a348d8"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define column names\n",
        "column_names = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']\n",
        "\n",
        "# Check the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the current directory\n",
        "print(\"Files in the directory:\", os.listdir())\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('iris(1).csv', header=None, names=column_names)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "\n",
        "    # Display the first few rows of the dataset\n",
        "    print(\"First five rows of the dataset:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Mapping string values in the Target column to numerical values\n",
        "    target_mapping = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n",
        "    df['Target'] = df['Target'].map(target_mapping)\n",
        "\n",
        "    # Verifying the changes\n",
        "    print(\"\\nUpdated Target column:\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Files in the directory: ['.config', 'iris (1).xlsx', 'sample_data']\n",
            "Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqU9gnuF7exi"
      },
      "source": [
        "Make sure we have no null values, and if we have, remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU1E0ppR7aK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc67d4be-23d3-44e7-d9aa-e14ac507b73b"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define column names\n",
        "column_names = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']\n",
        "\n",
        "# Check the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the current directory\n",
        "print(\"Files in the directory:\", os.listdir())\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('iris(1).csv', header=None, names=column_names)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "\n",
        "    # Display the first few rows of the dataset\n",
        "    print(\"First five rows of the dataset:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Check for null values\n",
        "    print(\"\\nChecking for null values:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Remove rows with null values if any\n",
        "    if df.isnull().values.any():\n",
        "        print(\"\\nNull values detected! Removing rows with null values...\")\n",
        "        df = df.dropna()\n",
        "        print(\"Rows with null values removed.\")\n",
        "    else:\n",
        "        print(\"No null values found in the dataset.\")\n",
        "\n",
        "    # Mapping string values in the Target column to numerical values\n",
        "    target_mapping = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n",
        "    df['Target'] = df['Target'].map(target_mapping)\n",
        "\n",
        "    # Verifying the changes\n",
        "    print(\"\\nUpdated Target column:\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Files in the directory: ['.config', 'iris (1).xlsx', 'sample_data']\n",
            "Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN8Yei2k5e2i"
      },
      "source": [
        "#Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o7UadL-7zVD"
      },
      "source": [
        "##Finding different Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0dKEoLZ8Amr"
      },
      "source": [
        "First, find how many classes we have in our dataset (although it should always appear in the description of your dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgExYYDy72CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee3e8c2-1439-4a96-e24e-a6ec6f7c031c"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define column names\n",
        "column_names = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']\n",
        "\n",
        "# Check the current working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the current directory\n",
        "print(\"Files in the directory:\", os.listdir())\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('iris(1).csv', header=None, names=column_names)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "\n",
        "    # Display the first few rows of the dataset\n",
        "    print(\"First five rows of the dataset:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Mapping string values in the Target column to numerical values\n",
        "    target_mapping = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n",
        "    df['Target'] = df['Target'].map(target_mapping)\n",
        "\n",
        "    # Find and display unique classes in the 'Target' column\n",
        "    unique_classes = df['Target'].unique()\n",
        "    print(f\"Unique classes in the dataset: {unique_classes}\")\n",
        "    print(f\"Number of classes: {len(unique_classes)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Files in the directory: ['.config', 'iris (1).xlsx', 'sample_data']\n",
            "Error: The file 'iris(1).csv' was not found. Ensure it is in the current directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we8EBYvX8JrF"
      },
      "source": [
        "SO we have 3 classes of flowers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myjWSPheAWa6"
      },
      "source": [
        "Remember the basic formula that we used for Naive Bayes. <br>\n",
        "<img src=\"https://equatio-api.texthelp.com/svg/%5C%20P(%5Ctextcolor%7B%232B7FBB%7D%7BClass%7D%7C%5Ctextcolor%7B%23E94D40%7D%7BFeatures%7D)%3D%5Cfrac%7BP(%5Ctextcolor%7B%23E94D40%7D%7BFeatures%7D%7C%5Ctextcolor%7B%232B7FBB%7D%7BClass%7D)%5Ccdot%20P%5Cleft(%5Ctextcolor%7B%232B7FBB%7D%7BClass%7D%5Cright)%7D%7BP(%5Ctextcolor%7B%23E94D40%7D%7BFeatures%7D)%7D\" alt=\"P of open paren C l a. s s divides F of e a. t u r e s close paren equals the fraction with numerator P of open paren F of e a. t u r e s divides C l a. s s close paren times P of open paren C l a. s s close paren and denominator P of F of e a. t u r e s\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2UrbRnHAh_R"
      },
      "source": [
        "Since we have 3 classes, and 4 features, we need to calculate the following probabilities.<br>\n",
        "<img src=\"https://equatio-api.texthelp.com/svg/P(%5Ctextcolor%7B%232B7FBB%7D%7BClass_0%7D%7C%5Ctextcolor%7B%23E94D40%7D%7BF1%2CF2%2CF3%2CF4%7D)\" alt=\"P of open paren C l a. s s sub 0 divides F of 1 comma F of 2 comma F of 3 comma F of 4 close paren\"> <br>\n",
        "<img src=\"https://equatio-api.texthelp.com/svg/P(%5Ctextcolor%7B%232B7FBB%7D%7BClass_1%7D%7C%5Ctextcolor%7B%23E94D40%7D%7BF1%2CF2%2CF3%2CF4%7D)\" alt=\"P of open paren C l a. s s sub 1 divides F of 1 comma F of 2 comma F of 3 comma F of 4 close paren\"> <br>\n",
        "<img src=\"https://equatio-api.texthelp.com/svg/P(%5Ctextcolor%7B%232B7FBB%7D%7BClass_2%7D%7C%5Ctextcolor%7B%23E94D40%7D%7BF1%2CF2%2CF3%2CF4%7D)\" alt=\"P of open paren C l a. s s sub 2 divides F of 1 comma F of 2 comma F of 3 comma F of 4 close paren\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1vv6PrLBdLg"
      },
      "source": [
        "So in reality we need to calculate the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfolDf1zBlGQ"
      },
      "source": [
        "<img src=\"https://equatio-api.texthelp.com/svg/P_0%3DP(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_1%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_0%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_2%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_0%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_3%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_0%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_4%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_0%7D%7D)\" alt=\"P sub 0 equals P of open paren F sub 1 divides C l a. s s sub 0 close paren P of open paren F sub 2 divides C l a. s s sub 0 close paren P of open paren F sub 3 divides C l a. s s sub 0 close paren P of open paren F sub 4 divides C l a. s s sub 0 close paren\"><img src=\"https://equatio-api.texthelp.com/svg/P%5Cleft(%5Ctextcolor%7B%232B7FBB%7D%7BClass_0%7D%5Cright)\" alt=\"P of open paren C l a. s s sub 0 close paren\"><br><img src=\"https://equatio-api.texthelp.com/svg/P_1%3DP(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_1%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_1%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_2%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_1%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_3%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_1%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_4%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_1%7D%7D)\" alt=\"P sub 1 equals P of open paren F sub 1 divides C l a. s s sub 1 close paren P of open paren F sub 2 divides C l a. s s sub 1 close paren P of open paren F sub 3 divides C l a. s s sub 1 close paren P of open paren F sub 4 divides C l a. s s sub 1 close paren\"><img src=\"https://equatio-api.texthelp.com/svg/P%5Cleft(%5Ctextcolor%7B%232B7FBB%7D%7BClass_1%7D%5Cright)\" alt=\"P of open paren C l a. s s sub 1 close paren\"><br>\n",
        "<img src=\"https://equatio-api.texthelp.com/svg/P_2%3DP(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_1%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_2%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_2%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_2%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_3%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_2%7D%7D)P(%5Ctextcolor%7B%232B7FBB%7D%7B%5Ctextcolor%7B%23E94D40%7D%7BF_4%7D%7D%7C%5Ctextcolor%7B%23E94D40%7D%7B%5Ctextcolor%7B%232B7FBB%7D%7BClass_2%7D%7D)P%5Cleft(%5Ctextcolor%7B%232B7FBB%7D%7BClass_2%7D%5Cright)\" alt=\"P sub 2 equals P of open paren F sub 1 divides C l a. s s sub 2 close paren P of open paren F sub 2 divides C l a. s s sub 2 close paren P of open paren F sub 3 divides C l a. s s sub 2 close paren P of open paren F sub 4 divides C l a. s s sub 2 close paren P of open paren C l a. s s sub 2 close paren\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWodfMQv05nc"
      },
      "source": [
        "We see which one is the greatest, and based on that we assign the class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-YKGe4Q0mjD"
      },
      "source": [
        "Those probabilities will be approximated using a distribution.\n",
        "In this example, we will use the Gaussien Distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAcatx6x1A2L"
      },
      "source": [
        "##Gaussian Probability Density Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oj_NOLW1J-E"
      },
      "source": [
        "We recall that teh Gaussien Probability density function is given by:\n",
        "<br>\n",
        "<img src=\"https://equatio-api.texthelp.com/svg/f%5Cleft(x%5Cright)%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Ctextcolor%7B%238D44AD%7D%7B%5Csigma%7D%7D%5Cexp%5Cleft%5C%7B-%5Cfrac%7B%5Cleft(x-%5Ctextcolor%7B%233697DC%7D%7Bmean%7D%5Cright)%5E2%7D%7B2%5Ctextcolor%7B%238D44AD%7D%7B%5Csigma%7D%5E2%7D%5Cright%5C%7D\" alt=\"f of x equals 1 over the square root of 2 pi sigma the exp of open brace negative the fraction with numerator open paren x minus m e a. n close paren squared and denominator 2 sigma squared close brace\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A32D5STGrzX"
      },
      "source": [
        "Write a function that computes the probability using the formula above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZnRXZJA01nM"
      },
      "source": [
        "import math\n",
        "\n",
        "def gaussian_probability(x, mean, std_dev):\n",
        "    \"\"\"\n",
        "    Compute the Gaussian (normal) probability density function for a given x.\n",
        "\n",
        "    Parameters:\n",
        "    x : float : Feature value for which the probability is being calculated\n",
        "    mean : float : Mean of the feature values for the given class\n",
        "    std_dev : float : Standard deviation of the feature values for the given class\n",
        "\n",
        "    Returns:\n",
        "    float : Gaussian probability for the given feature value x\n",
        "    \"\"\"\n",
        "    exponent = math.exp(-((x - mean) ** 2) / (2 * (std_dev ** 2)))\n",
        "    return (1 / (math.sqrt(2 * math.pi) * std_dev)) * exponent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMpZQUyE1EnS"
      },
      "source": [
        "##Naive Bayes Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTp5JrZUHg1Z"
      },
      "source": [
        "Write a naive bayes function that receives as input the dataframe df, the features, and the target name, and it returns the predicted class as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-8D3Rxq_pbr"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def naive_bayes(df, features, target_name):\n",
        "\n",
        "\n",
        "    # Step 1: Calculate the class priors (P(Class))\n",
        "    class_priors = df[target_name].value_counts(normalize=True)  # P(Class)\n",
        "\n",
        "    # Step 2: Calculate mean and std deviation for each feature per class\n",
        "    mean_std_per_class = {}\n",
        "    for label in class_priors.index:\n",
        "        class_data = df[df[target_name] == label]\n",
        "        mean_std_per_class[label] = {\n",
        "            feature: (class_data[feature].mean(), class_data[feature].std())\n",
        "            for feature in features\n",
        "        }\n",
        "\n",
        "    # Step 3: Gaussian Probability Density Function for continuous data\n",
        "    def gaussian_probability(x, mean, std_dev):\n",
        "        exponent = np.exp(-((x - mean) ** 2) / (2 * (std_dev ** 2)))\n",
        "        return (1 / (np.sqrt(2 * np.pi) * std_dev)) * exponent\n",
        "\n",
        "    # Step 4: Calculate the posterior probability for each class\n",
        "    posteriors = {}\n",
        "    for label in class_priors.index:\n",
        "        prior = class_priors[label]  # P(Class)\n",
        "        likelihood = 1  # P(Feature | Class), initially set to 1\n",
        "\n",
        "        # Calculate likelihood for each feature in the class\n",
        "        for feature in features:\n",
        "            feature_value = df[feature]\n",
        "            mean, std_dev = mean_std_per_class[label][feature]\n",
        "            likelihood *= gaussian_probability(feature_value, mean, std_dev)\n",
        "\n",
        "        # Posterior probability is P(Class) * P(Features | Class)\n",
        "        posteriors[label] = prior * likelihood\n",
        "\n",
        "    # Step 5: Predict the class with the highest posterior probability\n",
        "    # Use np.argmax to find the class with the highest posterior probability\n",
        "    predicted_class = np.argmax([posteriors[label] for label in class_priors.index])\n",
        "\n",
        "    return predicted_class\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWXRIkmoGDyV"
      },
      "source": [
        "Test Naive Bayes with a prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYjRWvNwIAlV"
      },
      "source": [
        "Get the corresponding class for a flower having the following features [4.9, 3.0,\t1.4,\t0.2]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Q66_iiH4FL"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def naive_bayes(df, features, target_name, new_data):\n",
        "\n",
        "\n",
        "    # Step 1: Calculate the class priors (P(Class))\n",
        "    class_priors = df[target_name].value_counts(normalize=True)  # P(Class)\n",
        "\n",
        "    # Step 2: Calculate mean and std deviation for each feature per class\n",
        "    mean_std_per_class = {}\n",
        "    for label in class_priors.index:\n",
        "        class_data = df[df[target_name] == label]\n",
        "        mean_std_per_class[label] = {\n",
        "            feature: (class_data[feature].mean(), class_data[feature].std())\n",
        "            for feature in features\n",
        "        }\n",
        "\n",
        "    # Step 3: Gaussian Probability Density Function for continuous data\n",
        "    def gaussian_probability(x, mean, std_dev):\n",
        "        exponent = np.exp(-((x - mean) ** 2) / (2 * (std_dev ** 2)))\n",
        "        return (1 / (np.sqrt(2 * np.pi) * std_dev)) * exponent\n",
        "\n",
        "    # Step 4: Calculate the posterior probability for each class\n",
        "    posteriors = {}\n",
        "    for label in class_priors.index:\n",
        "        prior = class_priors[label]  # P(Class)\n",
        "        likelihood = 1  # P(Feature | Class), initially set to 1\n",
        "\n",
        "        # Calculate likelihood for each feature in the class\n",
        "        for i, feature in enumerate(features):\n",
        "            feature_value = new_data[i]\n",
        "            mean, std_dev = mean_std_per_class[label][feature]\n",
        "            likelihood *= gaussian_probability(feature_value, mean, std_dev)\n",
        "\n",
        "        # Posterior probability is P(Class) * P(Features | Class)\n",
        "        posteriors[label] = prior * likelihood\n",
        "\n",
        "    # Step 5: Predict the class with the highest posterior probability\n",
        "    predicted_class = np.argmax([posteriors[label] for label in class_priors.index])\n",
        "\n",
        "    return predicted_class\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSylYkiz15zU"
      },
      "source": [
        "See the performance of our NB model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCvhS9H04sku"
      },
      "source": [
        "Now here we will splot our data between 2 sets:\n",
        "\n",
        "*   One from which the Naive Bayes Model will take the probabilities. (The **old** set) 80%\n",
        "*   one that it hasn't seen before to test on it (The **new** set) 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5UUqMI24XTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9acf44c-3524-41ca-ab25-c287095bf863"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import pi, sqrt, exp\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "column_names = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']\n",
        "file_path = 'iris(1).csv'\n",
        "\n",
        "# Check if the file exists in the current directory\n",
        "if not os.path.isfile(file_path):\n",
        "    print(f\"The file {file_path} does not exist. Please check the file name and path.\")\n",
        "else:\n",
        "    # Loading dataset\n",
        "    df = pd.read_csv(file_path, header=None, names=column_names)\n",
        "\n",
        "    # Map target labels to numeric values\n",
        "    target_mapping = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n",
        "    df['Target'] = df['Target'].map(target_mapping)\n",
        "\n",
        "    # Step 2: Splitting the dataset (80% training, 20% testing)\n",
        "    features = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width']\n",
        "    target_name = 'Target'\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[target_name]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 3: Implement Naive Bayes Function\n",
        "    def gaussian_probability(x, mean, std_dev):\n",
        "        return (1 / (sqrt(2 * pi) * std_dev)) * exp(-0.5 * ((x - mean) ** 2) / (std_dev ** 2))\n",
        "\n",
        "    def naive_bayes(df, features, target_name):\n",
        "        # Step 4: Calculate class probabilities and conditional probabilities\n",
        "        # Calculate P(C)\n",
        "        class_probs = df[target_name].value_counts(normalize=True).to_dict()\n",
        "\n",
        "        # Calculate mean and std dev for each feature and class\n",
        "        feature_stats = {}\n",
        "        for feature in features:\n",
        "            feature_stats[feature] = {}\n",
        "            for class_value in class_probs:\n",
        "                class_subset = df[df[target_name] == class_value]\n",
        "                feature_stats[feature][class_value] = {\n",
        "                    'mean': class_subset[feature].mean(),\n",
        "                    'std': class_subset[feature].std()\n",
        "                }\n",
        "\n",
        "        # Step 5: Make prediction for a given data point\n",
        "        def predict(features_values):\n",
        "            # Calculate the probability for each class\n",
        "            probabilities = {}\n",
        "            for class_value in class_probs:\n",
        "                class_prob = class_probs[class_value]\n",
        "                feature_probs = 1\n",
        "                for i, feature in enumerate(features):\n",
        "                    mean = feature_stats[feature][class_value]['mean']\n",
        "                    std = feature_stats[feature][class_value]['std']\n",
        "                    feature_prob = gaussian_probability(features_values[i], mean, std)\n",
        "                    feature_probs *= feature_prob\n",
        "                probabilities[class_value] = class_prob * feature_probs\n",
        "            return max(probabilities, key=probabilities.get)\n",
        "\n",
        "        return predict\n",
        "\n",
        "    # Step 6: Train Naive Bayes Model\n",
        "    naive_bayes_model = naive_bayes(df, features, target_name)\n",
        "\n",
        "    # Step 7: Make Predictions on Test Set\n",
        "    predictions = []\n",
        "    for index, row in X_test.iterrows():\n",
        "        predicted_class = naive_bayes_model(row[features].values)\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    # Step 8: Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Accuracy of the Naive Bayes model on the test set: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file iris(1).csv does not exist. Please check the file name and path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blWBczqaIeMR"
      },
      "source": [
        "Now use the function you built and get the corresponding testing predictions, and then compute the accuracy of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qEvL2Rv1r8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5d3b41-dd7f-4bcf-c9c1-01645fff5cfa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import pi, sqrt, exp\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "column_names = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width', 'Target']\n",
        "file_path = 'iris(1).csv'\n",
        "\n",
        "# Check if the file exists in the current directory\n",
        "if not os.path.isfile(file_path):\n",
        "    print(f\"The file {file_path} does not exist. Please check the file name and path.\")\n",
        "else:\n",
        "    # Loading dataset\n",
        "    df = pd.read_csv(file_path, header=None, names=column_names)\n",
        "\n",
        "    # Map target labels to numeric values\n",
        "    target_mapping = {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n",
        "    df['Target'] = df['Target'].map(target_mapping)\n",
        "\n",
        "    # Step 2: Splitting the dataset (80% training, 20% testing)\n",
        "    features = ['Sepal Height', 'Sepal Width', 'Petal Height', 'Petal Width']\n",
        "    target_name = 'Target'\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[target_name]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 3: Implement Naive Bayes Function\n",
        "    def gaussian_probability(x, mean, std_dev):\n",
        "        return (1 / (sqrt(2 * pi) * std_dev)) * exp(-0.5 * ((x - mean) ** 2) / (std_dev ** 2))\n",
        "\n",
        "    def naive_bayes(df, features, target_name):\n",
        "        # Step 4: Calculate class probabilities and conditional probabilities\n",
        "        # Calculate P(C)\n",
        "        class_probs = df[target_name].value_counts(normalize=True).to_dict()\n",
        "\n",
        "        # Calculate mean and std dev for each feature and class\n",
        "        feature_stats = {}\n",
        "        for feature in features:\n",
        "            feature_stats[feature] = {}\n",
        "            for class_value in class_probs:\n",
        "                class_subset = df[df[target_name] == class_value]\n",
        "                feature_stats[feature][class_value] = {\n",
        "                    'mean': class_subset[feature].mean(),\n",
        "                    'std': class_subset[feature].std()\n",
        "                }\n",
        "\n",
        "        # Step 5: Make prediction for a given data point\n",
        "        def predict(features_values):\n",
        "            # Calculate the probability for each class\n",
        "            probabilities = {}\n",
        "            for class_value in class_probs:\n",
        "                class_prob = class_probs[class_value]\n",
        "                feature_probs = 1\n",
        "                for i, feature in enumerate(features):\n",
        "                    mean = feature_stats[feature][class_value]['mean']\n",
        "                    std = feature_stats[feature][class_value]['std']\n",
        "                    feature_prob = gaussian_probability(features_values[i], mean, std)\n",
        "                    feature_probs *= feature_prob\n",
        "                probabilities[class_value] = class_prob * feature_probs\n",
        "            return max(probabilities, key=probabilities.get)\n",
        "\n",
        "        return predict\n",
        "\n",
        "    # Step 6: Train Naive Bayes Model\n",
        "    naive_bayes_model = naive_bayes(df, features, target_name)\n",
        "\n",
        "    # Step 7: Make Predictions on Test Set\n",
        "    predictions = []\n",
        "    for index, row in X_test.iterrows():\n",
        "        predicted_class = naive_bayes_model(row[features].values)\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    # Step 8: Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Accuracy of the Naive Bayes model on the test set: {accuracy * 100:.2f}%\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file iris(1).csv does not exist. Please check the file name and path.\n"
          ]
        }
      ]
    }
  ]
}